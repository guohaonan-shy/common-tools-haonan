# Redis 常用知识点:
## Redis的数据结构：
redis总共有五种常用数据类型，key对象都是string，value对象可能是string、list、hashmap、set以及sorted set;  
根据数据size的不同，底层实现的方式可能有所不同

### 字符串对象:
日常项目中，最常用的对象就是字符串对象，用来作为某些对象的缓存或者某些整数、布尔的简单计算  
字符串的底层实现分为三种：
1. int类型，当存储内容为整型或者long类型的整数时，由于整数占用空间小，因此直接存储在对象内，不需要额外空间；同时方便频繁的数字计算
2. embstr类型，当存储的字符串的长度小于某个阈值(不同版本不一样咯)，即该redis对象为一块连续完整的内存，对象基本信息之后紧跟一个sds对象
3. raw类型，redis对象里存有一个指向sds内存块的指针

#### int类型：
当存储对象是整型或long类型的整数时，一般会按照int编码的方式进行存储，整型一般为1～8个字节，占用空间小，无需额外存储分配，直接存入对象即可；  
同时，执行INCR等命令时，无需转换为字符串，直接进行整型计算，减少了类型转换的开销；

##### 当存储对象为浮点数或者字符串的时候，底层会用紧凑型字符串(embstr)或者原生的字节数组(raw)，由对象大小决定
#### embstr类型：
set一个字符串键时，根据字符串的长度决定编码类型，当字符串对象较小时，redis会为该对象分配一块连续的内存(对象类型，编码类型以及存储内容的sds)
#### raw类型：
当embstr对象超过了阈值或对象初始大小较大时，redis会为该对象分配两块内存，一块是存有字符串内容的sds，另一块则是redis对象并指向对应的sds

##### embstr相比于raw，内存分配和内存释放的次数各少了一次，减少内存操作意味着减少系统调用从而提升命令执行的效率；同时减少因额外分配空间释放导致的内存碎片
##### 同时连续的内存空间，无需额外寻址；因此可以方便利用缓存的特性，进一步优化查询性能(当然我觉得这块差别很微小)

### 列表对象：
列表对象指对应的键存有一系列对象，底层是由ziplist或者linkedlist实现
#### ziplist:
当列表内元素大小较小并且总的元素个数比较少的时候，列表对象会分配一块连续的内存存储列表对象及其元素对象们  
ziplist可看作编程语言中的数组，对象之间的内存连续
```
type ziplist struct {
    zlbytes int // 该字段用来存储ziplist总共占据内存多少字节空间
    zltail int //  尾指针，主要代表该ziplist内存起始地址到尾节点之间的偏移字节
    zllen int // 长度，即元素个数
    content []zipnode 指向具体元素存储的内存，是一个compacted array
    zlend int // 结束字节
}

type zipnode struct {
    previous_entry_size 1个字节或者5个字节 // 用来描述该节点的前一节点的内存大小，使得尾节点可以向前索引  
    encoding_type // 长度为1，2或者5字节，当该字段仅一个字段时，该entry内存的元素是整型元素；若为2或5字节，则该entry内存的事字节数组，同时包含数组的长度
    content // 具体内容
}
```
从上面ziplist的结构可以看出，每个node是一个可能变化的结构，比如LPUSH、LPOP，从列表头插入或者删除一个元素，那么每个节点的previous_entry_size可能都会发生变化，那么相应节点的内存以及后续节点的位置都需要移动，
极端情况下，每个元素的previous_entry_size都发生变化，整体的时间复杂度会退化到O(N^2)

#### linkedlist:
当元素大小较大或者元素个数较多时，ziplist会升级为双向链表，链表中每个对象都是一个string对象，如上所述

### 哈希对象：
哈希对象底层实现是ziplist或者dict字典，压缩列表的结构上面已经介绍过了，只不过哈希对象会按照键值对一个键和一个值交替存入压缩列表
#### dict实现：
当元素比较多且元素大小比较大时，redis会使用字典对哈希对象进行编码实现，采用seperate chaining的方式，字典内持有两个hashmap，一般情况下只使用第一个，
当hashmap因负载因子过高触发扩容，伴随着hash的增删改查，会进行渐进式的rehash，将对应桶内的数据重新分配到新表内。

##### 插入元素：
- 计算key的hash值进行路由
- 路由到对应的slot， 如果slot存在元素，则追加到该槽位的链表

##### 删除元素
- 计算key的hash值进行路由
- 遍历对应的slot的链表，删除对应元素

### 集合对象：
普通的集合对象根据元素类型和元素数目决定底层实现是intset(整数集合)or hashmap
#### intset：
若该集合内的元素都为整数且元素数目较少时，会使用整型集合作为底层实现
```
type intset struct {
    encoding uint32 // 整型元素的编码方式，决定底层数组的元素类型是int16, int32还是int64
    length uint32 // 当前集合数组的长度
    content []intxx // 集合数组，元素类型取决于encoding的方式，元素唯一且有序(为了唯一性判断方便，二分)    
}
```

如果元素类型为其他或者元素数目比较多时，底层会采用hashmap进行实现，只不过value存的是null对象

### 有序集合对象：
底层实现是ziplist或者skiplist，如果是ziplist，content则会存集合的元素及其分数值
如果是skiplist的实现方式，zset内会包含一个字典以及跳表
```
type zset struct {
    skiplist // 用logN的复杂度索引到指定的集合元素
    dict // 字典主要是为根据分数快速索引到集合对象
}
```
如果用普通的列表+实时的排序实现有序集合，则每次插入新的元素之后都要用快排对列表进行重排序  
插入元素：时间复杂度是O(NlogN)，空间复杂度为O(logN);   
查询对象: 二分查找也可将查询复杂度控制在O(logN);  
移除元素：平移动剩下的元素，平均时间复杂度为O(N)

##### 那么跳表相比于普通列表的优势在哪？

跳表的本质是在有序列表上建立多级索引，假设链表的长度为N且每两个节点之间抽一个索引，则一级索引的个数为N/2，二级索引为N/4，直到第k级索引为1  

那么总共多出来的索引节点个数为N/2 + N/4 + ...... + 1 = 2^k - 1，k=logN, 即结果为N-1，其实就是用额外的空间，将查询的时间复杂度优化为了O(logN)  

##### 跳表索引的建立和更新：  
程序在将元素插入到有序列表的同时，判断该索引等级是否需要添加索引，一般的方法(包括redis中zset的实现)，均为如下方法：  

第一层索引有N/2个索引，即每个元素作为第一层索引的概率为1/2；  
第二层索引有N/4个索引，即每个元素作为第二层索引的概率为1/4;  
第k层索引，即最高层，只有一个索引，那么某个元素成为该层索引的概率为1/2^k;  

这种方法最坏的情况就是插入元素需要在每层安排一个索引，那么先在对应层寻找索引要插入的位置，然后插入，时间复杂度为O(logN1+logN2 + ......+logN)，即O(logN)；

删除元素时，需要从最高层开始一直到存有元素对象的链表中，每层都先查询该元素是否存在索引，有则删除，删除索引复杂度也是一样

## redis + os
### redis的线程模型：
早期的redis是一个单线程模型，因为redis主要都是内存读写操作，执行十分迅速，因此cpu并非是瓶颈；

主要的瓶颈是在网络I/O的传输延时以及磁盘文件的持久化上，即I/0瓶颈，所以redis采用了单线程+事件模型+I/O多路复用进行系统搭建

优点是
1. 由于单线程的设计，redis对内存的读写无需引入同步变量来处理竞态条件，且无需进行线程之间的切换，系统的性能进一步提升
2. I/O多路复用+异步执行的方式无阻塞，在一个事件循环内，epoll或者kqueue会轮询所有其下的socket套接字，当其可读或者可写，执行对应的事件逻辑

### I/O多路复用
#### 连接事件：  
server在启动的时候，会根据自己的ip:port生成一个server的socket接收其他client的连接请求；  
当server的socket有可读事件时，server进程内会创建新的socket用于client和server之间的通信；

#### 命令请求和相应事件：
当client发送命令请求redis server的执行，在事件循环中多路复用epoll或者kqueue，会监听所有的socket是否可操作；  
当socket可操作时，说明缓冲区内读写内容已经ready，进行命令的操作以及对client的响应

## redis的持久化
redis的持久化主要有两种方式，一种是RDB，另外一种是AOF  
RDB是redis某个时刻内存的数据快照，AOF则是所有写命令的日志文件；server启动时，都可以借助二者进行数据的恢复

### RDB(数据快照)
RDB是redis某个时刻的内存数据快照，同server最新的数据是有差距的，因此从数据一致性的角度，RDB可能会有数据的缺失

RDB文件的生成有两种方式一种是停机生成(SAVE)，另一种是后台生成(BGSAVE);

SAVE是停机生成RDB文件，因此该方法生成的快照即是最新的，但是停机对用户使用的影响比较大，一般很少使用

BGSAVE是主进程fork一个子进程出来，采用写时复制的方式：
1. 起初两个进程共享内存存储；  
2. 当主进程继续接收写命令，对某些内存进行修改，根据写时复制，有修改的这部分内存页会进行复制，然后修改复制的副本； 
3. 待RDB文件重写完成，子进程结束，子进程信号通知主进程并替换RDB文件

从写时复制的过程能看到，RDB是上一次fork的数据快照，fork进程到进程结束之间的写命令没有被存下来，因此当server宕机，之后在用RDB进行数据恢复时，这部分命令会丢失掉

因此RDB一般用于主从架构中，从服务器从对应的主服务器获取对应的RDB文件然后进行数据初始化，增量的命令通过命令连接进行通信

### AOF(写命令的日志)
AOF是写命令的日志集合，每当执行一行写命令之后，server会将该命令按照指定协议格式写入AOF缓冲区，每轮事件循环按照指定的策略写入AOF文件

一般有三种AOF写入策略：
1. always：将AOF缓冲区内的内容写入并同步到AOF文件内
2. everyseconds: 将AOF缓冲区内的内容写入文件内，如果上次AOF文件同步的时间超过1s，redis会将文件缓冲的内容刷入磁盘文件
3. no:将AOF缓冲区内的内容写入文件内，但是不进行同步，同步是由操作系统决定

always数据一致性最高，但是性能也是要求最高的，因为每轮事件循环都需要进行中断刷盘  
everyseconds是一个较为全面的选择；no则可能会将数据堆在fd内的缓冲区内，导致数据丢失

随着系统的运行，AOF文件会越来越大，加载和维护的系统成本也越来越大，因此需要根据当前的内存数据，对AOF进行重写，精简文件内容，因此需要AOF重写

#### AOF重写
AOF重写(BGSAVEAOF)：也是fork一个子进程，采用写时复制进行重写
1. 子进程将当前内存内容，按照写命令进行重写，比如某个list对象内包含3，4，5三个元素，历史操作可能很多很多，但是重写只会以一条或者多条命令记录，比如`lpush key 3，4，5`
2. 主进程继续接收命令提供服务，但是写命令会写入一个AOF重写缓冲区，记录增量命令
3. 子进程通知主进程重写完成，此时主进程会短暂停机一小会儿，便于缓冲区内容append到新aof文件后面，并进行文件替换
4. 主进程恢复

### 这块有个操作系统的概念，需要和redis本身的设计区分开来  

对于read和write这类系统调用来说，其实文件描述符也是有对应的缓存区的，并不是write 16bytes就是立马完成的

当某个fd的写缓冲区已满，因此新的内容无法写入，此时线程会阻塞等待直到缓冲区内容同步写入文件，然后将新的内容写入缓冲区完成；

当程序读取某个fd，但此时可读缓冲区内容不足n bytes，那么线程会阻塞直到缓冲区内容满足n bytes，并将内容读出

#### 这里则有个关于非阻塞I/O和异步I/O的概念
非阻塞I/O: 当I/O操作没有满足执行条件，比如读缓冲内容不足，那么该I/O并不会阻塞而是不执行返回给调用方，一般需要程序或者事件模型轮询维护，eg. epoll

异步I/0: 类似于异步RPC，调用处可继续执行后续程序，当该I/O执行完成后，通过信号或者通信告诉线程

## redis的分布式架构

### redis集群
redis集群架构通过数据分片的方式，数据键通过`slot = CRC(key) % 16384`得到该键对应的插槽，从而路由到对应的节点中进行操作

redis集群总共有16384个插槽，构建集群的时候，按照某个方式，将这些槽分配给每一个节点(这时候默认都是主节点)，节点之间通过消息互通知道了整个集群的slot维护情况；

```
type redisServer struct {
    ...
    *clusterState state
    ...
}

type ClusterState struct {
    ...
    *clusterNode myself     // 指向当前节点
    int64 epoch             // 纪元，主要用来进行集群的重新分片以及故障转移时使用
    int state               // 集群在线or下线，集群只有在所有的slot均分配节点时才能上线ready
    map[string]*clusterNode // 整个集群内所有的节点信息
    [16384]*clusterNode     // 每个插槽维护的节点信息，通过该信息，每个server节点可以判断命令操作的slot是否是本节点，若不是，则返回给client一个moved错误，客户端会重定向到指定节点
    skipList slot_to_key    // 跳表，score是具体的slot编号，内容则是插槽内对应的数据键，便于数据迁移
    
    ...
    // 负责迁移和导入的数据结构
    [16384]*clusterNode  importing_slots_from
    [16384]*clusterNode  migrating_slots_to
    ...
}

type clusterNode struct { 
    ...
    [2048]byte slots // 通过一个长16384/8个字节的比特数组存储本节点维护的slot
    int numslots
    *link link // 用于连接节点的连接信息，网络ip、port之类的
    ...
}
```

### redis的主从架构
主从架构是分布式系统可用性维护的常用方案：
1. 首先集群通过冗余和备份避免了单点故障，并分散了流量，对于redis来说，集群式的部署将数据的写入分散到了多个节点，即使一个节点宕机、也并不会影响整个集群作为整体去提供服务；
2. 其次主从架构+读写分离实现了数据的备份和冗余，主节点负责处理写请求以及部分延时要求较高的读请求，从节点负责处理绝大部分的读请求；一份数据在主从节点多份冗余和备份，即使某个节点出现了问题，也能通过快速的处理继续提供服务
3. 主从节点的水平扩容也很简单：
   1. 从节点只需要指定主节点，即可在集群内添加一个以主节点为复制对象的从节点，从节点通过加载主节点的RDB文件进行数据初始化，之后通过主从之间的数据推拉实现增量写命令的同步  
   `什么是推拉，推指的是主节点作为从节点的client定期或者立马将写命令发送到从节点server；拉是指从服务器定期检测和主的连接状况，从返回的信息获取到主节点复制缓冲区的offset，如果大于从节点，说明从节点现在数据落后，主节点会将offset这部分cmd发送给从节点补齐缺失数据`
   2. 主节点的水平扩容，则需要进行数据的重分片，首先对slot进行重新分配，部分slot需要分配给新增加的主节点进行管理
      1. redis提供数据迁移的中间件，按照插槽的纬度迁移数据，将插槽内的每个key迁移到目标节点；redis的中间件从源节点获取到对应插槽的所有key，通过clusterState内跳表快速索引获取数据
      2. 然后一个个插槽开始迁移，首先先将源节点的import和目标节点的migrating数组更新，之后开始迁移
      3. 增量的命令，先判断当前key的slot是否在本节点，如果不在，则重定向到新的节点；如果在，需要判断该slot是否正在迁移，如果在迁移ing，我个人认为这块需要双写(当然这块也可以判断key是否在新节点)，待迁移完成之后，再修改slot信息
   
### sentinel(哨兵)
哨兵也是一种redis高可用的架构解决方案，哨兵节点通过监视集群内的主节点以及从节点，来进行故障处理

哨兵实例启动，需要指定或者配置该哨兵监听的主节点信息，哨兵会定时给其治下的主节点和从节点发送info指令，获取最新的主节点及其从节点信息，更新哨兵内维护的节点信息

这块有个特别的设计，就是哨兵通过命令连接向治下每个节点发送信息，然后通过订阅频道向所以管理该节点的所有哨兵节点广播该源节点返回的信息，通过该方法，哨兵之间可以维护与其他哨兵的关系，并建立哨兵之间的连接(用于选举)

此时，每个哨兵节点维护了与其管理的主从节点的tcp连接以及其余哨兵节点的连接，每秒向这些连接发送心跳信号，判断实例是否在线；ping没有在指定事件收到回复，哨兵会主动判断目标节点下线

#### redis的故障转移
##### 哨兵选主
当某个主节点主观下线了，哨兵节点通过向其他哨兵节点请求，当指定数目的哨兵节点也判断该主节点主观下线了，此时哨兵标记该节点为客观下线，需要重新选主

但是选主之前，首先要现在哨兵之间选择一个主导本次选主的节点，当某个或者某几个哨兵判定某个主节点客观下线了，这几个哨兵节点会触发选举过程，向所有哨兵发送投票请求，请求投自己作为leader，接收哨兵节点按照时间先后确定自己的投票情况；
当某个哨兵获取到了半数的投票，它成为leader，并开始存储节点的选主
##### 存储节点选主
首先哨兵主节点会筛选出可用的从节点，即仍然保持和哨兵的连接且最近回复过哨兵info指令的节点，之后在从节点中，选择优先级最高且offset最大(数据最新的)的节点作为新的主节点；之后修改所有从节点的复制目标进行数据同步，将原先的主节点修改为从节点(手动或者自动化运维？)

## redis的“事务”
redis本质上没有事务的，只不过redis的客户端通过设置一个指令队列，如果可以执行，会以来redis的单线程模型，将一串原子指令执行完成

某个redis client先通过MULTI指令声明事务开始，然后将要执行的指令放入队列但不执行，之后调用EXEC执行队列内所有的指令；

但是执行MULTI指令和EXEC之间是有时间差的，这个过程中队列指令要修改的对象可能被其他的client修改，这样某个事务执行的前置条件可能发生变化，因此需要引入WATCH指令对目标key进行监视，如果发生修改，事务exec时会直接报错，不会执行事务，程序可以调用DISCARD发起队列内的指令

本质上redis的事务不存在原子性，因为不会回滚，但是redis开发的角度上，一般指令执行错误都是因为使用者自己的错误导致的，所以redis按照原子性的原则全部执行了事务的指令，只不过部分成功、部分失败

### 和pipeline的区别
pipeline并非事务队列内所有的指令顺序一起执行，而是多个cmd指令批量操作，最后以一次I/0形式返回所有指令的返回
## redis缓存